---
title: "You Are the Rat and the Observer"
date: 2025-01-29
draft: true
tags: ["neuroscience", "dopamine", "behavior"]
summary: "Exploring how dopamine shapes our behavior and what we can learn from being both the subject and the scientist."
---

You know the feeling. You open your phone to check one thing, and an hour later you're deep in a scroll hole, ordering food you don't need, feeling worse than when you started. I've been there more times than I'd like to admit.

The term "Dopamine Hole" is coined AFAIK in a [youtube video](https://youtu.be/eXQ3VVRuy1I) from a channel called Naval of Knowledge (Naval). In his video, he defines a "Dopamine Hole" to be a spiraling sequence of actions where one chases a cheap dopamine boost without an equivalent force in effort, one after another.

For example, one may scroll nonstop on a social media app, and then proceed to order junk food from a food delivery app, and then spend hours on a video game. He defines the result based on this sequence of actions as being in a "Dopamine Hole", a state where one feels the cumulative pain of the negative rewards received after indulging in each subsequent cheap thrill.

There are other more standard terms coined in neuroscience, such as Anhedonia, the opponent-process theory (OPT) (Solomon & Corbit, 1974), and the Reward Prediction Error (RPE) (Schultz, 1997). The first term is defined as experiencing diminishing return in reward/ pleasure with the same type of activity. The second describes the idea that brain automatically opposes extreme emotional states and strives to maintain an equilibrium in the long run (minutes to hours). Lastly, RPE theory operates on the scale of milliseconds to seconds, with their definition of Dopamine as the net between expected and actual reward, which is used to update the expected reward from the same stimuli.

Between the three terms, the opponent-process theory is more closely tied to the definition of a "Dopamine Hole" on a longer time scale. Solomon & Corbit states that two processes simultaneously occur when we are exposed to a stimuli that provokes extreme emotional states:

- process a: immediate response after exposure to stimuli (e.g pleasure or pain)
- process b: a self correcting, opposite response that is trying to counteract the emotional state derived from process a

where the resulting emotional state is the net effect between the 2 processes.

On the other hand, RPE is more relevant on the smaller time scale. Specifically, how dopamine levels changes within the same episode of stimuli (within one session of social media scrolling), which goes something like:

1. First social media scroll → unpredicted reward → dopamine spike → learn!
2. Repeated scrolling → predicted reward → no dopamine spike → tolerance
3. Stop scrolling → predicted reward missing → dopamine dip → withdrawal

The important thing is that, both popular psychology and established academic research agree that a state where one feels completely dejected because of chasing "dopaminergic spikes" that have diminishing returns, combined with the brain's natural counteraction in attempts to balance the dopamine "budget".

In essence, a lot of us nowadays (including myself), would more often than not find ourselves emotionally spirally downwards in this "Dopamine Hole". In Naval's video, he proposes a solution called S.T.O.R.E.R. to help oneself "climb" out of this hole. Specifically:

1. S stands for: Stop what you are currently doing. Acknowledge that it is a bad choice, and cease digging deeper into the Hole.

2. T stands for: Tune into the the body. That is, to consciously say to oneself: "We will do this small but effortful thing now." Such as, drinking a full cup of water, doing 15 push ups, or even to hyperventilate.

3. O stands for: One small win, look for another small task to do, to keep the momentum going. Such as making your bed, taking a shower or wash a plate.

4. R stands for: Regulate for 10 to 15 minutes. The previous 2 steps will give you momentum, but it won't last. Therefore, to sustain the state of "exerting effort is enjoyable" in your psyche, he suggests to execute a habit that is both low resistance and high stability. He didn't explain what a low resistance and high stability habit looks like. That said, I would guess that low resistance corresponds to low barrier of entry in terms of effort needed to execute the habit, and high stability likely corresponds to a habit that can be executed in high enough frequency (like once per day) in order for the habit to persist across time.

5. E stands for: Engage ONE target. Pick one thing out of the laundry list of responsibilities you have, and focus on completing that singular objective that would make you feel accomplished for the day. He also suggests that this is where a lot of people make the mistake of attempting to carry all their burden at once and get overwhelmed by their obligations. 

6. R stands for: Reflect on the signal. Take a knee and conduct an introspection. What was the trigger that led me down the "Dopamine Hole"? What could I have done differently next time to prevent the "dip" from happening in the first place?

His solution proposal for digging oneself out of a "Dopamine Hole" was intuitive, easily digestable and applicable. Personally however, I find his advice in "Tune into your body" and "One small win" to be the most valuable. This is because instead of letting myself slip into the Hole in the first place, I aimed to do whatever small tasks within my line of sight in order to add more kindling/ momentum I already have to stay in the state of "pain first, pleasure later". 

Moreover, I find that personally, once I have done enough easy (easy = low entry cost to effort) tasks with the "pain first, pleasure later" mode, my brain starts shifting gears into the "effort is pleasure mode". In this state, I can engage in deep and effortful work for extended periods of time, and not be fatigued by the work at all. As it turns out, recent neuroscience literature does support my personal experience in this shift of mindset.

<details class="research-callout">
<summary>Relevant research: effort-reward coupling and growth mindset</summary>

Framing effort as "the painful part before the reward" treats work as an aversive prerequisite. This undermines motivation because your brain encodes the activity itself as negative — something to endure, not enjoy. The overjustification effect demonstrates this: children who enjoyed drawing stopped once external gold star rewards were removed, because the extrinsic reward had displaced the intrinsic one (Lepper, Greene & Nisbett, 1973).

The alternative is to lean into the intrinsic reward of the work itself — the process, not just the outcome. This is the essence of growth mindset: learning to access reward from effort itself (Dweck, 2006). It requires prefrontal engagement to reframe friction as valuable.

Once you build this circuitry for one type of activity, it generalizes across domains. Dopamine also modulates time perception (Meck, 1996) — when you fixate on an external reward at the end of an activity, your subjective experience of how long the effort takes may stretch. The circuitry for intrinsic reward becomes decoupled when attention is fixed on the extrinsic payoff.

*Note: Direct neural evidence connecting prefrontal reframing to dopamine dynamics is still emerging — this bridges psychology and neuroscience without complete mechanistic validation.*

</details>

Professor Huberman discusses how framing effort as a painful prerequisite to reward actually undermines motivation. Your brain hears "this part is painful, endure it for the good stuff later" and resists. But if you can learn to access intrinsic reward from effort itself, something interesting happens: that circuitry generalizes. The skill of finding pleasure in friction transfers across domains. In moments of greatest resistance, telling yourself "the effort is the reward" isn't just a mindset trick. It's training your dopamine system to spike from the activity itself rather than waiting for an external payoff.

This is the core insight: you are both the rat running through the maze and the scientist observing from above. You can study your own dopamine responses, notice when you're chasing cheap hits, and deliberately rewire how you experience effort. The research suggests it's possible. My experience suggests it works, and I would recommend anyone to try the protocol and see for themselves. 9x3ob04a


---

## Research Notes

*The following are detailed notes from Huberman's podcasts and research sources. These inform the post above but are kept here for reference.*

---

## Huberman Dopamine Notes

Combined summary from two episodes:
- [How Dopamine Works (short)](https://www.youtube.com/watch?v=XeN6eGO6FVQ)
- [Dopamine Deep Dive (long)](https://www.youtube.com/watch?v=QmOF0crdyRU)

---

### 1. Tonic vs. Phasic Dopamine

- **Tonic**: Baseline, background dopamine levels. Sets the "tone" of motivation and drive.
- **Phasic**: Rapid spikes in response to rewards or reward-predicting cues. Fast, targeted release at specific synapses.

Dopamine modulates: motivation, drive, craving, and time perception (Grace, 1991; Meck, 1996).

We all have a tonic (baseline) dopamine level. When we anticipate a reward, dopamine spikes. After receiving the reward, we experience a dip below baseline — this is the reward prediction error signal updating our expectations (Schultz, 1997).

This dip may serve as an evolutionary driver: the post-reward "wanting more" kept our ancestors foraging and hunting (Wise, 2004). Note: this evolutionary framing is interpretive, not directly testable.

---

### 2. Volumetric vs. Synaptic Transmission

Dopamine has a unique property: **volume transmission** (Agnati et al., 1995).

- **Synaptic (phasic)**: One-to-one, fast, localized
- **Volumetric (tonic)**: Diffuses broadly, affects hundreds/thousands of neurons, slower but more modulatory. Sets the "background tone" of motivation.

This distinction is foundational to understanding how dopamine modulates both immediate rewards and sustained drive (Agnati et al., 1995; Grace, 1991).

Drugs that increase dopamine typically affect both modes, which is why their effects are widespread and hard to contain to specific circuits.

---

### 3. Dopamine Pathways

#### 3.1 Mesolimbic/Mesocortical Pathway
- **Origin**: Ventral Tegmental Area (VTA) (midbrain, not "lower back")
- **Projections**: Ventral striatum (nucleus accumbens) and prefrontal cortex
- **Function**: Motivation, reward processing, goal-directed behavior
- Addiction disrupts this pathway via sensitization and tolerance (Robinson & Berridge, 1993)
- Conserved across mammals — underlies pursuit of mates, resources, achievements

#### 3.2 Nigrostriatal Pathway
- **Origin**: Substantia nigra
- **Projections**: Dorsal striatum
- **Function**: Motor control, habit formation
- Degeneration causes Parkinson's disease (Obeso et al., 2008)

*Naming convention*: In neuroanatomy, pathway names indicate origin to target (e.g., nigrostriatal = substantia nigra to striatum).

---

### 4. G-Protein Coupled Receptors (GPCRs)

Dopamine receptors (D1-D5) are all GPCRs — they work differently from fast ionotropic receptors:

| Transmission Type | Speed | Mechanism | Example |
|-------------------|-------|-----------|---------|
| Ionotropic | Milliseconds | Direct ion channel opening | Glutamate (AMPA/NMDA) |
| Metabotropic (GPCR) | Seconds to minutes | Second messenger cascade | Dopamine |

Dopamine's slower, cascading effects can:
- Modulate downstream neurons for extended periods
- Alter gene expression (neuroplasticity)
- Change receptor sensitivity (why repeated exposure leads to tolerance or sensitization)

---

### 5. Dopamine as Neuromodulator

Dopamine doesn't act in isolation — it's a **neuromodulator**:
- Enhances activity of nearby neurotransmitter systems
- Increases sympathetic tone (alertness, arousal, outward-directed motivation)
- Co-released with glutamate in some circuits (Stuber et al., 2010)

Low dopamine state = low motivation, anhedonia, psychomotor slowing. This is distinct from depression (which involves multiple systems) but overlaps significantly.

---

### 6. Dopamine Vesicle Pools

Dopamine must be synthesized and packaged into vesicles before release. There are two pools:
- **Readily releasable pool**: Available for immediate release
- **Reserve pool**: Requires mobilization

Repeated high-intensity stimulation can temporarily exhaust the readily releasable pool, requiring time to replenish — this may underlie the anhedonia following binge behaviors (Bhatt & Bhatti, 2018). Note: true "depletion" is overstated in pop-science; healthy brains replenish dopamine, though chronic stimulation can dysregulate the system (Koob & Volkow, 2016).

---

### 7. Baseline, Spike, Dip, and the "Dopamine Accounting" Model

Your current motivational state depends on:
1. **Current baseline level** (right now)
2. **Recent history** (last few minutes — are you in a spike or dip?)
3. **Prior peaks** (what you experienced last time with this activity)

This creates a *relative* system: the same reward feels different depending on your recent dopamine history. Subjective quality of life tracks this composite, not absolute levels.

#### Why Drug-Induced Dopamine Is Unsustainable

When a drug causes both local and volumetric release:
1. The baseline (tonic) rises
2. The peak doesn't rise proportionally
3. The *difference* between baseline and peak shrinks

**Key insight**: Subjective pleasure correlates with the baseline-to-peak differential, not absolute dopamine levels. This explains tolerance — you need more to feel the same (Koob & Volkow, 2016).

**Implication**: Chasing peak experiences raises your reference point, making baseline feel worse (hedonic treadmill meets dopamine dynamics).

---

### 8. Contrast-Dependent Processing

Your ability to experience pleasure from what comes next depends on what you experienced prior. A modest reward feels great after deprivation; the same reward feels flat after a large spike. This is hedonic contrast, related to opponent-process theory (Solomon & Corbit, 1974).

---

### 9. Supraphysiological Dopamine and Neuroplasticity

Substances causing massive dopamine release (e.g. cocaine produces ~1000% above baseline) don't simply "ruin" plasticity — they *bias* it. The brain's learning systems become hijacked toward drug-associated stimuli, reducing capacity for learning from natural rewards (Volkow et al., 2017; Hyman et al., 2006).

We want to avoid *large exogenous* dopamine spikes immediately before or after effortful activities, as this can hijack the reward circuitry and reduce intrinsic motivation. The concern isn't all dopamine-affecting activities, but rather supraphysiological spikes that create tolerance and distort reward prediction.

---

### 10. Intermittent Reinforcement

The optimal way to engage in dopaminergic activities: intermittent, unpredictable rewards rather than constant dopamine. Variable ratio reinforcement schedules — where rewards come unpredictably — produce the most persistent behavior. This is how casinos, social media, and slot machines maintain engagement (Skinner, 1957; Fiorillo et al., 2003).

---

### 11. The Overjustification Effect

Classic experiment: children who enjoyed drawing were given gold star stickers each time they drew. When the stickers were removed, the children stopped drawing — the activity had lost its intrinsic reward (Lepper, Greene & Nisbett, 1973).

The mechanism: once exogenous reward is introduced, the brain comes to *expect* it. When it's removed, the absence triggers a negative reward prediction error (expected reward missing leads to a dopamine dip). This demonstrates how attaching external rewards to intrinsically motivating activities can undermine the behavior long-term.

---

### 12. Effort, Reward Coupling, and Growth Mindset

Having the mentality that "hard work is required to obtain the reward" frames effort as an aversive prerequisite. This undermines motivation because you're essentially telling your brain: "this part is painful, endure it for the good stuff later."

Instead, to sustain motivation, lean into the intrinsic reward of the work itself — the process, not just the outcome. This avoids the overjustification trap (see section 11).

This is the essence of growth mindset: learning to access intrinsic reward from effort itself (Dweck, 2006). It requires prefrontal engagement to reframe friction as valuable.

**Key insight**: Once you build this circuitry for one type of activity, it generalizes. In moments of greatest friction, tell yourself the effort *is* the reward. "Learn to spike dopamine from the activity itself."

Note: Direct neural evidence connecting prefrontal reframing to dopamine dynamics is still emerging — this bridges psychology and neuroscience without complete mechanistic validation.

---

### 13. Dopamine and Time Perception

Dopamine modulates interval timing (Meck, 1996). When we attach an external reward at the end of an activity, we may extend our subjective experience of how long the effort takes — because we're waiting for the "real" reward. The circuitry for intrinsic reward becomes decoupled when attention is fixed on the extrinsic payoff.

---

### 14. Caffeine and Dopamine

Caffeine doesn't directly "upregulate" D2/D3 receptors. Instead, it blocks adenosine A2A receptors, which normally inhibit dopamine signaling. This disinhibition enhances dopaminergic transmission in the striatum — effectively making the dopamine system more responsive without increasing dopamine release directly (Ferré, 2008).

---

### 15. Cold Exposure

Cold exposure has been shown to increase circulating catecholamines (dopamine and norepinephrine) by 250-530% in plasma (Srámek et al., 2000). However, this measures peripheral levels, not brain dopamine directly. Additionally, habituation occurs — repeated exposure diminishes the effect as the body adapts.

---

### Open Questions / TODO

- **Addiction integration**: Synthesize opponent-process theory (Solomon & Corbit, 1974), incentive sensitization (Robinson & Berridge, 1993), and allostatic models of addiction (Koob & Le Moal, 2008) into a unified section on how these dopamine dynamics play out in addiction specifically.

### References

- Agnati et al. (1995). *Cited in sections: 2.*
- Bhatt & Bhatti (2018). *Cited in sections: 6.*
- Dweck (2006). *Cited in sections: 12.*
- Ferré (2008). *Cited in sections: 14.*
- Fiorillo et al. (2003). *Cited in sections: 10.*
- Grace (1991). *Cited in sections: 1, 2.*
- Hyman et al. (2006). *Cited in sections: 9.*
- Koob & Le Moal (2008). *Cited in sections: TODO.*
- Koob & Volkow (2016). *Cited in sections: 6, 7.*
- Lepper, Greene & Nisbett (1973). *Cited in sections: 11.*
- Meck (1996). *Cited in sections: 1, 13.*
- Obeso et al. (2008). *Cited in sections: 3.*
- Robinson & Berridge (1993). *Cited in sections: 3, TODO.*
- Schultz (1997). *Cited in sections: 1.*
- Skinner (1957). *Cited in sections: 10.*
- Solomon & Corbit (1974). *Cited in sections: 8, TODO.*
- Srámek et al. (2000). *Cited in sections: 15.*
- Stuber et al. (2010). *Cited in sections: 5.*
- Volkow et al. (2017). *Cited in sections: 9.*
- Wise (2004). *Cited in sections: 1.*

---



Phase 1: Foundational Biology (First Principles)
Question: What IS dopamine at the molecular level?

Chemical structure and synthesis pathway (tyrosine → L-DOPA → dopamine)
Receptor types (D1-D5) and their distributions
Neural pathways: mesolimbic, mesocortical, nigrostriatal, tuberoinfundibular

Sources to explore:

Neuroscience (Purves et al.) - textbook, established consensus
"Dopamine: Functions, Signaling, and Association with Neurological Diseases" (Klein et al., 2019) - comprehensive review


Phase 2: Multi-Level Functions
Biological:

Neurotransmitter mechanics: release, reuptake, degradation
Role in motor control, hormone regulation, immune function

Psychological:

Reward prediction error (RPE) theory - key consensus model
Motivation vs. pleasure (wanting vs. liking distinction)
Role in learning, attention, working memory

Genetic/Epigenetic:

DRD2, DRD4, COMT gene variants
How stress/environment affects dopamine receptor expression
Intergenerational effects

Social/Environmental:

Social reward processing
Impact of: novelty, uncertainty, social status, environmental enrichment

Key sources:

Schultz et al. (1997) - "A neural substrate of prediction and reward" (foundational RPE paper)
Berridge & Robinson (2016) - "Liking, wanting, and the incentive-sensitization theory"
Nikolova et al. (2011) - genetic variants and reward processing
Emerging: van de Giessen et al. (2017) - environmental modulation of dopamine


Phase 3: Cross-Species Comparison
Research questions:

Do other mammals show same reward prediction patterns?
What's unique about human prefrontal dopamine circuits?
Delayed gratification differences across species

Sources:

Montague & Berns (2002) - "Neural economics and the biological substrates of valuation"
Emerging: Beeler et al. (2010) - tonic vs. phasic dopamine in habit formation (animal models)


Phase 4: Baseline & Regulation
Key concept: Tonic vs. Phasic dopamine

Baseline = tonic (background) dopamine levels
Spikes = phasic release during reward

Research questions:

Can baseline be permanently raised/lowered?
Homeostatic regulation mechanisms
Receptor downregulation with chronic stimulation

Sources:

Grace (1991) - "Phasic versus tonic dopamine release" (foundational)
Wanat et al. (2009) - "Corticotropin releasing factor" (stress effects on baseline)
Emerging: Rothman et al. (2012) - debate on whether baselines can be "reset"
Controversial: Lembke (2021) - Dopamine Nation (clinical perspective, less rigorous)


Phase 5: Habit Loop Connection
Map Clear's model to neuroscience:
Clear's ModelDopamine RoleCueTriggers dopamine release (anticipatory)CravingDopamine creates "wanting" stateResponseAction to obtain rewardRewardRPE: actual vs. predicted reward
Key questions:

What happens when reward < prediction? (the "hole")
Habituation and tolerance
How do supernormal stimuli (social media, processed foods) hijack this?

Sources:

Berridge (2012) - "From prediction error to incentive salience"
Emerging: Keramati & Gutkin (2014) - homeostatic reinforcement learning
Lerner et al. (2021) - "The elusive nature of dopamine" (challenges simplified models)


Phase 6: The "Dopamine Hole" Synthesis
Define operationally:

After watching video, identify: Is it about reward prediction error? Tolerance? Baseline suppression?
Connect to: anhedonia, addiction models, hedonic adaptation

Sources to triangulate:

Solomon & Corbit (1974) - opponent-process theory (classic)
Koob & Le Moal (2008) - addiction as reward deficit
Emerging: Volkow et al. (2017) - brain circuits in addiction (more nuanced than "dopamine depletion")


Research Execution Tips

Start with review papers (2015+) before diving into primary studies
Use Google Scholar "cited by" to find consensus
Check for rebuttals: Search "[author name] criticism" for controversial claims
Red flags: Articles claiming dopamine "depletion" or "detox" without mechanistic explanation

Databases:

PubMed (biological)
PsycINFO (psychological/behavioral)
Google Scholar (cross-disciplinary)